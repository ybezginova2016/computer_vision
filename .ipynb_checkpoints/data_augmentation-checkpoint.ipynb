{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV (Open Computer Vision): Data Augmentation\n",
    "\n",
    "Аугментации используются, чтобы улучшить обучение. Все преобразования изображений — преобразования NumPy-массивов. В большинстве случаев для аугментации хватает готовых библиотек, которые вы изучите позднее, но иногда придётся создавать методы с помощью OpenCV и других библиотек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('/Users/yuliabezginova/Downloads/Lena.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[125 137 226]\n",
      "  [125 137 226]\n",
      "  [133 137 223]\n",
      "  ...\n",
      "  [122 148 230]\n",
      "  [110 130 221]\n",
      "  [ 90  99 200]]\n",
      "\n",
      " [[125 137 226]\n",
      "  [125 137 226]\n",
      "  [133 137 223]\n",
      "  ...\n",
      "  [122 148 230]\n",
      "  [110 130 221]\n",
      "  [ 90  99 200]]\n",
      "\n",
      " [[125 137 226]\n",
      "  [125 137 226]\n",
      "  [133 137 223]\n",
      "  ...\n",
      "  [122 148 230]\n",
      "  [110 130 221]\n",
      "  [ 90  99 200]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 60  18  84]\n",
      "  [ 60  18  84]\n",
      "  [ 58  27  92]\n",
      "  ...\n",
      "  [ 84  73 173]\n",
      "  [ 76  68 172]\n",
      "  [ 79  62 177]]\n",
      "\n",
      " [[ 57  22  82]\n",
      "  [ 57  22  82]\n",
      "  [ 62  32  96]\n",
      "  ...\n",
      "  [ 79  70 179]\n",
      "  [ 81  71 181]\n",
      "  [ 81  74 185]]\n",
      "\n",
      " [[ 57  22  82]\n",
      "  [ 57  22  82]\n",
      "  [ 62  32  96]\n",
      "  ...\n",
      "  [ 79  70 179]\n",
      "  [ 81  71 181]\n",
      "  [ 81  74 185]]]\n"
     ]
    }
   ],
   "source": [
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Отображение изображение по вертикали и горизонтали"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenCV открывает изображение в цветовой модели BGR — RGB с другим порядком каналов. Чтобы вернуть его в стандартный вид, достаточно развернуть порядок классическим для Питона способом: image[...,::-1].\n",
    "\n",
    "Отражение можно сделать разными способами:\n",
    "\n",
    "- ##### Встроенными средствами Питона\n",
    "\n",
    "  Оператор, которым вы развернули порядок каналов, может изменить и изображение. Достаточно выбрать нужное измерение и развернуть порядок строк. Отражение по горизонтали осуществляется так: image[:,::-1,:]. Если же поменять первое измерение, то произойдёт вертикальное отражение. \n",
    "\n",
    "- ##### NumPy\n",
    "\n",
    "  В NumPy есть специальный метод flip, который принимает массив и ось, по которой надо сделать флип. 0 — вертикальный флип, 1 — горизонтальный, 2 — в области каналов: например, np.flip(image, 1).\n",
    "\n",
    "- ##### OpenCV\n",
    "\n",
    "  В OpenCV идентичный NumPy синтаксис: cv2.flip(image, 1). Однако флип по каналам так сделать нельзя, в OpenCV cv2.cvtColor преобразует каналы и цветовые модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = image[:,::-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 90,  99, 200],\n",
       "        [110, 130, 221],\n",
       "        [122, 148, 230],\n",
       "        ...,\n",
       "        [133, 137, 223],\n",
       "        [125, 137, 226],\n",
       "        [125, 137, 226]],\n",
       "\n",
       "       [[ 90,  99, 200],\n",
       "        [110, 130, 221],\n",
       "        [122, 148, 230],\n",
       "        ...,\n",
       "        [133, 137, 223],\n",
       "        [125, 137, 226],\n",
       "        [125, 137, 226]],\n",
       "\n",
       "       [[ 90,  99, 200],\n",
       "        [110, 130, 221],\n",
       "        [122, 148, 230],\n",
       "        ...,\n",
       "        [133, 137, 223],\n",
       "        [125, 137, 226],\n",
       "        [125, 137, 226]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 79,  62, 177],\n",
       "        [ 76,  68, 172],\n",
       "        [ 84,  73, 173],\n",
       "        ...,\n",
       "        [ 58,  27,  92],\n",
       "        [ 60,  18,  84],\n",
       "        [ 60,  18,  84]],\n",
       "\n",
       "       [[ 81,  74, 185],\n",
       "        [ 81,  71, 181],\n",
       "        [ 79,  70, 179],\n",
       "        ...,\n",
       "        [ 62,  32,  96],\n",
       "        [ 57,  22,  82],\n",
       "        [ 57,  22,  82]],\n",
       "\n",
       "       [[ 81,  74, 185],\n",
       "        [ 81,  71, 181],\n",
       "        [ 79,  70, 179],\n",
       "        ...,\n",
       "        [ 62,  32,  96],\n",
       "        [ 57,  22,  82],\n",
       "        [ 57,  22,  82]]], dtype=uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image2 = cv2.flip(image, 1)\n",
    "image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  4, 114, 226],\n",
       "        [  4, 114, 226],\n",
       "        [  1, 103, 223],\n",
       "        ...,\n",
       "        [  7, 120, 230],\n",
       "        [  5, 128, 221],\n",
       "        [  2, 140, 200]],\n",
       "\n",
       "       [[  4, 114, 226],\n",
       "        [  4, 114, 226],\n",
       "        [  1, 103, 223],\n",
       "        ...,\n",
       "        [  7, 120, 230],\n",
       "        [  5, 128, 221],\n",
       "        [  2, 140, 200]],\n",
       "\n",
       "       [[  4, 114, 226],\n",
       "        [  4, 114, 226],\n",
       "        [  1, 103, 223],\n",
       "        ...,\n",
       "        [  7, 120, 230],\n",
       "        [  5, 128, 221],\n",
       "        [  2, 140, 200]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[161, 200,  84],\n",
       "        [161, 200,  84],\n",
       "        [166, 180,  92],\n",
       "        ...,\n",
       "        [177, 147, 173],\n",
       "        [178, 154, 172],\n",
       "        [176, 166, 177]],\n",
       "\n",
       "       [[163, 187,  82],\n",
       "        [163, 187,  82],\n",
       "        [166, 170,  96],\n",
       "        ...,\n",
       "        [178, 155, 179],\n",
       "        [177, 155, 181],\n",
       "        [178, 153, 185]],\n",
       "\n",
       "       [[163, 187,  82],\n",
       "        [163, 187,  82],\n",
       "        [166, 170,  96],\n",
       "        ...,\n",
       "        [178, 155, 179],\n",
       "        [177, 155, 181],\n",
       "        [178, 153, 185]]], dtype=uint8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image3 = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "image3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Яркость\n",
    "\n",
    "Чтобы увеличить яркость изображения, прибавьте к нему определённое число. Это значит, что нужно взять каждое значение канала по всем пикселям на картинке и увеличить его на X. Остальные операции выполняются аналогично: увеличить или уменьшить контраст — умножить на число, а изменить гамму — возвести в степень. Эти операции выполняются очень просто: например, image+10 увеличит яркость, а image-10 — уменьшит. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[135, 147, 236],\n",
       "        [135, 147, 236],\n",
       "        [143, 147, 233],\n",
       "        ...,\n",
       "        [132, 158, 240],\n",
       "        [120, 140, 231],\n",
       "        [100, 109, 210]],\n",
       "\n",
       "       [[135, 147, 236],\n",
       "        [135, 147, 236],\n",
       "        [143, 147, 233],\n",
       "        ...,\n",
       "        [132, 158, 240],\n",
       "        [120, 140, 231],\n",
       "        [100, 109, 210]],\n",
       "\n",
       "       [[135, 147, 236],\n",
       "        [135, 147, 236],\n",
       "        [143, 147, 233],\n",
       "        ...,\n",
       "        [132, 158, 240],\n",
       "        [120, 140, 231],\n",
       "        [100, 109, 210]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 70,  28,  94],\n",
       "        [ 70,  28,  94],\n",
       "        [ 68,  37, 102],\n",
       "        ...,\n",
       "        [ 94,  83, 183],\n",
       "        [ 86,  78, 182],\n",
       "        [ 89,  72, 187]],\n",
       "\n",
       "       [[ 67,  32,  92],\n",
       "        [ 67,  32,  92],\n",
       "        [ 72,  42, 106],\n",
       "        ...,\n",
       "        [ 89,  80, 189],\n",
       "        [ 91,  81, 191],\n",
       "        [ 91,  84, 195]],\n",
       "\n",
       "       [[ 67,  32,  92],\n",
       "        [ 67,  32,  92],\n",
       "        [ 72,  42, 106],\n",
       "        ...,\n",
       "        [ 89,  80, 189],\n",
       "        [ 91,  81, 191],\n",
       "        [ 91,  84, 195]]], dtype=uint8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image4 = np.clip((image.astype(np.int32) + 10), 0, 255).astype(np.uint8)\n",
    "image4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
